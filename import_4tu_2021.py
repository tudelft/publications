# Download HTML
import requests
from lxml import html
import codecs
from time import sleep # this should go at the top of the file

from selenium import webdriver
from selenium.webdriver.chrome.options import Options

from habanero import cn


opts = Options()
opts.add_argument("--headless")
opts.add_argument("--disable-gpu")
opts.add_argument("--no-sandbox")
opts.add_argument("start-maximized")
opts.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...")

driver = webdriver.Chrome(options=opts)


URL_4TU = 'https://data.4tu.nl'


list_of_dois = []


def download_list(search, bibf):

    url = URL_4TU + '/search?q=' + search

    bibf.write('\n# Searching: '+  url +'\n')  

    done = False
    while not done:

        driver.get(url)
        sleep(5)
        html = driver.execute_script("return document.getElementsByTagName('html')[0].innerHTML")
        # print(html)

        print('Downloaded ' + url + '.\n')

        f = html.split('https://data.4tu.nl/datasets/')
        for ff in f:
            if '<head>' in ff:
                continue

            doi = ff.split('">')[0]
            doi = '10.4121/' + doi.replace('/','.v')

            bibf.write('#  - '+  doi +'\n')  
            print(doi)
            list_of_dois.append(doi)

        done = True




def get_doi(doi):

    # remove the '10.4121/' prefix and everything after the trailing '.v'
    doi = doi.replace('10.4121/', '')
    if '.v' in doi:
        doi = doi.split('.v')[0]

    url = 'https://data.4tu.nl/datasets/' + doi

    # download the page and find the first occurrence of 'https://doi.org/'
    response = requests.get(url)
    if response.status_code != 200:
        print('Error: Could not access URL ' + url)
        return ''
    html_content = response.text
    start_index = html_content.find('https://doi.org/')
    if start_index == -1:
        print('Error: DOI not found in the page content.')
        return ''
    end_index = html_content.find('"', start_index)
    if end_index == -1:
        print('Error: Could not find the end of the DOI link.')
        return ''

    return html_content[start_index + len('https://doi.org/'):end_index]


searchterms = ['de croon', 'de wagter', 'smeur', 'remes', 'tijmons', 'hamaza', 'popovic']


bibf = codecs.open( 'fourtu.bib', 'w', 'utf-8')
bibf.write(u'\ufeff')
bibf.write('# AUTOGENERATED\n# Import from: '+  URL_4TU +'\n\n\n')


for s in searchterms:
    download_list(s, bibf)


unique = set(list_of_dois)
print('Found ' + str(len(unique)) + ' unique DOIs.\n')

# Iterate over unique DOIs and download bibtex entries
for doi in unique:
    print('Downloading bibtex for ' + doi)

    bibf.write('# UUID: ' + doi + '\n\n')
    doi = get_doi(doi)
    bibf.write('# DOI:  ' + doi + '\n\n')

    print('Converted DOI to ' + doi)

    try:
        bib = cn.content_negotiation(ids=doi, format="bibentry")
        bib = bib.replace('}, ', '},\n\t')
        bibf.write(bib + '\n\n')
    except Exception as e:
        print('Error downloading bibtex for ' + doi + ': ' + str(e))
        continue


bibf.close()