# Download HTML
import requests
from lxml import html
import codecs
import json

#from requests_html import HTMLSession

def download_list(page, filename):

    url = 'https://dataverse.nl/dataverse/mavlab'

    if page == 0:
        bibf = codecs.open(filename,'w', 'utf-8')
        bibf.write(u'\ufeff')
        bibf.write('# AUTOGENERATED\n# Import from: '+url+'\n\n\n')
        bibf.close()

    papernr = 1
    pageno = page
    if True:
        print('- Page',pageno)
        
        p = requests.get(url) # + '&page=%d' % pageno)
        print('Downloaded...\n')

        # Download dataverse page
        dom = html.fromstring(p.text.encode('utf-8'))

        # Get lines with dataset links
        interest = [s.strip("\r\n").strip().strip('<a href="').split('"')[0] for s in p.text.splitlines(True) if '/dataset.xhtml?persistentId=doi:' in s and not 'icon-dataset' in s]

        #parser = etree.HTMLParser(recover=True)
        #tree = etree.fromstring(url, parser=parser)
        for p in interest:
            pp = p.strip('/dataset.xhtml?persistentId=doi:')
            print(pp)

            #session = HTMLSession()
            #r = session.get('https://www.doi2bib.org/bib/'+ pp)
            #r.html.render()
            #txt = r.html.text #find('code')
            #print(txt)
            
            #txt = doi_to_bib(pp, False, False)
            #print(pp, txt)

            # Accept: text/bibliography; style=bibtex
            headers = {"Accept": "text/bibliography; style=bibtex"}
            #headers = {"Content-Type": "text/bibliography; style=bibtex"}
            payload = {'fromIds': True, 'input': pp, 'targetFormat': "Bibtex"}
            url = 'https://api.paperpile.com/api/public/convert'
            
            print(payload, '->', url)

            #pa = requests.get('http://doi.org/'+pp, headers=headers) #.replace('/','%2F'))
            #txt = pa.text
            #print(txt)
            txt = 'Fail... do manually'
            start = False
            bib = []
            for s in txt.splitlines(True):
                if '</textarea>' in s:
                    start = False
                if start:
                    bib.append(s.replace('@misc','@data').strip('\r\n'))
                if '<textarea' in s:
                    start = True
            if True: #len(bib) == 0:
                print('Error: no data:')
                print(txt)


            
            bib = '\n'.join(bib)
            bib = bib.replace('&quot;', '\"')
            bib = bib.replace('https://doi.org/','')
                        
            # open and add, in case of error one can continue
            bibf = codecs.open(filename,'a', 'utf-8')
            #bibf.write('# '+str(pageno)+', '+str(papernr)+'\n')
            bibf.write('# '+'https://dataverse.nl'+p+'\n\n')
            bibf.write(bib)
            bibf.write('\n')
            bibf.close()

            papernr += 1

            # continue if at least 1 paper was found.
            #done = False
            #break

        pageno += 1

        # debug: stop after 1 page
        #if pageno >= 1:
        #    done = True

     


download_list(0, 'dataverse.bib')
